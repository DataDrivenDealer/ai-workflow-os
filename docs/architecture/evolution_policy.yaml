# Evolution Policy Configuration
# Defines how evolution signals are collected, aggregated, and acted upon
# Version: 1.1.0
#
# Part of AEP-2: Evolution Closed-loop Automation
# Updated for AEP-6: Meta-Evolution Monitoring

version: "1.1.0"

# =============================================================================
# SIGNAL COLLECTION
# =============================================================================
collection:
  # Where signals are stored
  storage:
    per_project: "projects/{project_id}/evolution_signals.yaml"
    global_aggregate: "reports/evolution_aggregate.yaml"
  
  # Signal types (from kernel/evolution_signal.py)
  signal_types:
    - id: "rule_friction"
      description: "A rule blocked a legitimate action"
      severity_weight: 1.5
    - id: "missing_skill"
      description: "Needed capability not available"
      severity_weight: 1.2
    - id: "ambiguous_guidance"
      description: "Instruction was unclear"
      severity_weight: 1.0
    - id: "threshold_tension"
      description: "Success criteria too strict/loose"
      severity_weight: 1.3
    - id: "scope_escape"
      description: "Task needed to touch out-of-scope area"
      severity_weight: 1.4
    - id: "tooling_gap"
      description: "Missing automation/script"
      severity_weight: 1.1
  
  # Severity levels
  severity_levels:
    low: 1
    medium: 2
    high: 3
    critical: 5

# =============================================================================
# AGGREGATION RULES
# =============================================================================
aggregation:
  # When to trigger automatic aggregation
  triggers:
    # Count-based trigger
    signal_count:
      enabled: true
      threshold: 5  # Aggregate after N signals
      window: "7d"  # Within this time window
    
    # Severity-based trigger (weighted sum)
    severity_score:
      enabled: true
      threshold: 10  # Weighted severity sum
      calculation: "sum(severity_level * severity_weight for each signal)"
    
    # Time-based trigger (regardless of count)
    periodic:
      enabled: true
      interval: "weekly"
      day: "monday"
      time: "09:00"
  
  # Grouping for analysis
  grouping:
    primary: "signal_type"
    secondary: "rule_id"
    tertiary: "project_id"

# =============================================================================
# REVIEW TRIGGERS
# =============================================================================
review:
  # When to alert human for review
  alert_conditions:
    # Immediate alert (don't wait for aggregation)
    immediate:
      - severity: "critical"
      - signal_type: "rule_friction"
        rule_id: "R4"  # Data protection violations always immediate
    
    # Aggregated alert thresholds
    aggregated:
      same_rule_friction:
        count: 3
        window: "7d"
        action: "flag_for_rule_review"
      
      same_missing_skill:
        count: 2
        window: "14d"
        action: "flag_for_skill_addition"
      
      threshold_tension:
        count: 3
        window: "30d"
        action: "flag_for_threshold_calibration"
  
  # Report generation
  report:
    output_path: "reports/evolution_review_{date}.md"
    format: "markdown"
    include:
      - summary_statistics
      - signals_by_type
      - signals_by_rule
      - recommended_actions
      - historical_comparison

# =============================================================================
# AUTO-ACTIONS (Non-destructive)
# =============================================================================
auto_actions:
  # Actions that can be taken automatically (human still approves changes)
  enabled: true
  
  actions:
    generate_report:
      trigger: "aggregation_complete"
      action: "python scripts/aggregate_evolution_signals.py --generate-report"
      output: "reports/evolution_review_{date}.md"
    
    create_review_task:
      trigger: "review_threshold_reached"
      action: "create_task"
      task_template:
        title: "Review Evolution Signals: {signal_count} signals accumulated"
        priority: "P2"
        queue: "governance"
        assignee: "human"
    
    notify:
      trigger: "critical_signal"
      action: "log_warning"
      message: "Critical evolution signal logged: {signal_id}"

# =============================================================================
# EVOLUTION LIFECYCLE
# =============================================================================
lifecycle:
  # Signal states
  states:
    - new           # Just logged
    - aggregated    # Included in aggregate
    - reviewed      # Human has seen it
    - actioned      # Change made in response
    - dismissed     # Decided not to act
  
  # State transitions
  transitions:
    - from: "new"
      to: "aggregated"
      trigger: "aggregation_run"
    - from: "aggregated"
      to: "reviewed"
      trigger: "human_review"
    - from: "reviewed"
      to: "actioned"
      trigger: "change_committed"
    - from: "reviewed"
      to: "dismissed"
      trigger: "human_dismiss"
  
  # Retention
  retention:
    actioned_signals: "365d"
    dismissed_signals: "90d"
    raw_signals: "30d"  # Before aggregation

# =============================================================================
# REGRESSION PREVENTION
# =============================================================================
regression:
  # Before any evolution change is committed
  pre_commit_checks:
    - name: "prompt_count"
      command: "(Get-ChildItem .github/prompts/*.prompt.md).Count -ge 11"
      description: "Ensure no prompts were accidentally deleted"
    
    - name: "kernel_tests"
      command: "pytest kernel/tests/ -q"
      description: "Ensure kernel functionality is preserved"
    
    - name: "adapter_validation"
      command: "python scripts/validate_project_adapter.py {project_id}"
      description: "Ensure adapter still implements interface"
    
    - name: "meta_model_integrity"
      command: "python scripts/validate_meta_model.py"
      description: "Ensure layer definitions are consistent"
  
  # Post-commit verification
  post_commit_checks:
    - name: "smoke_test"
      command: "python -c \"from kernel.config import load_project_adapter; load_project_adapter('dgsf')\""
      description: "Ensure adapter can still be loaded"

# =============================================================================
# METRICS & MONITORING
# =============================================================================
metrics:
  # Track evolution health
  tracked_metrics:
    - name: "signals_per_week"
      aggregation: "count"
      window: "7d"
      alert_threshold: 10  # Too many signals = system friction
    
    - name: "time_to_action"
      aggregation: "avg"
      unit: "days"
      alert_threshold: 14  # Signals should be addressed within 2 weeks
    
    - name: "dismissal_rate"
      aggregation: "ratio"
      calculation: "dismissed / (actioned + dismissed)"
      alert_threshold: 0.8  # If >80% dismissed, signals may be noise
  
  # Dashboard output
  dashboard:
    enabled: true
    output: "reports/evolution_dashboard.md"
    refresh: "daily"

# =============================================================================
# AEP-3: EVOLUTION EFFECTIVENESS TRACKING
# =============================================================================
# Closes the evolution loop by measuring whether applied changes improve the system

effectiveness:
  # Observation window after evolution is applied
  measurement_window: "30d"
  
  # Minimum signals before measuring (avoid noise from small samples)
  minimum_signals_for_measurement: 5
  
  # Success criteria for an evolution
  success_criteria:
    friction_reduction:
      description: "Same-type friction signals should decrease"
      operator: ">="
      value: 0.3  # 30% reduction in same-type friction
      measurement: "compare(signals_before, signals_after, same_type)"
    
    no_new_high_severity:
      description: "Evolution should not introduce high-severity friction"
      operator: "=="
      value: true
      measurement: "count(new_signals, severity >= high) == 0"
    
    no_regression:
      description: "Other metrics should not degrade"
      operator: "<="
      value: 0.1  # Max 10% degradation in any other metric
      measurement: "max_degradation(all_metrics)"
  
  # Automatic actions based on effectiveness
  actions:
    on_success:
      - action: "mark_evolution_verified"
      - action: "update_evolution_confidence"
        delta: +0.1
    
    on_failure:
      - action: "flag_for_rollback_review"
      - action: "create_task"
        template:
          title: "Review Evolution Effectiveness: {evolution_id}"
          priority: "P2"
          queue: "governance"
    
    on_insufficient_data:
      - action: "extend_measurement_window"
        extension: "14d"
        max_extensions: 2
  
  # Rollback mechanism
  rollback:
    enabled: true
    requires_human_approval: true
    
    # Conditions that trigger rollback consideration
    triggers:
      - condition: "effectiveness.success_criteria.friction_reduction not met"
        severity: "review"
      - condition: "effectiveness.success_criteria.no_new_high_severity not met"
        severity: "urgent"
      - condition: "effectiveness.success_criteria.no_regression not met"
        severity: "review"
    
    # How rollback is executed
    execution:
      method: "git_revert"
      branch: "evolution/{evolution_id}"
      requires_tests: true
      
  # Checkpoint management
  checkpoints:
    create_on: "evolution_applied"
    retention: "90d"
    naming: "checkpoint_{evolution_id}_{timestamp}"

# =============================================================================
# AEP-6: META-EVOLUTION MONITORING
# =============================================================================
# Second-order monitoring: the evolution system monitoring itself
# Addresses Tension C1: Self-referential measurement problem

meta_monitoring:
  enabled: true
  version: "1.0.0"
  
  # Health metrics for the evolution system itself
  health_metrics:
    signal_coverage:
      description: "Percentage of code paths covered by friction signal detection"
      target:
        operator: ">="
        value: 0.8
      measurement: "scripts/measure_signal_coverage.py"
      frequency: "weekly"
      
    evolution_velocity:
      description: "Average time from signal to implementation"
      target:
        operator: "<="
        value: "14d"
      measurement: "avg(actioned_at - first_signal_at)"
      frequency: "weekly"
      
    regression_rate:
      description: "Proportion of evolutions rolled back within 30 days"
      target:
        operator: "<="
        value: 0.1
      measurement: "count(rolled_back, 30d) / count(applied, 30d)"
      frequency: "monthly"
      
    blind_spot_proxy:
      description: "Proportion of new code paths with no signals after 7 days"
      target:
        operator: "<="
        value: 0.2
      measurement: "new_paths_without_signals / total_new_paths"
      frequency: "weekly"
      alert_threshold: 0.3  # Higher than target = potential blind spot expansion
      
    signal_noise_ratio:
      description: "Proportion of signals that lead to actionable changes"
      target:
        operator: ">="
        value: 0.3
      measurement: "count(actioned) / count(total)"
      frequency: "monthly"

  # Blind spot detection mechanism
  blind_spot_detection:
    enabled: true
    
    # Proactive detection: check new code paths
    proactive:
      enabled: true
      trigger: "new_code_path_added"
      action: "register_for_monitoring"
      monitoring_window: "7d"
      alert_if_no_signal: true
      
    # Passive detection: track cold zones
    passive:
      enabled: true
      cold_zone_threshold: "30d"  # No friction signal for this long
      action: "flag_for_manual_review"
      report_path: "reports/cold_zones_{date}.md"
      
    # Coverage tracking
    coverage:
      track_by: ["module", "skill", "rule"]
      report_frequency: "weekly"
      report_path: "reports/signal_coverage_{date}.md"

  # Evolution A/B testing (optional, for high-impact changes)
  ab_testing:
    enabled: false  # Enable when needed for major evolutions
    
    configuration:
      control_percentage: 10
      treatment_percentage: 10
      minimum_sample_size: 50  # Experiments before conclusion
      duration: "14d"
      
    success_criterion:
      metric: "friction_rate"
      direction: "decrease"
      minimum_delta: 0.2  # 20% reduction required
      
    auto_rollback:
      enabled: true
      trigger: "friction_rate_increase > 0.1"
      
  # Self-monitoring triggers
  self_monitoring:
    frequency: "weekly"
    report_path: "reports/meta_evolution_health_{date}.md"
    
    alerts:
      - metric: "blind_spot_proxy"
        condition: "> 0.3"
        severity: "high"
        action: "flag_for_coverage_review"
        
      - metric: "evolution_velocity"
        condition: "> 21d"
        severity: "medium"
        action: "flag_for_process_review"
        
      - metric: "regression_rate"
        condition: "> 0.15"
        severity: "high"
        action: "pause_auto_evolution"
        
      - metric: "signal_noise_ratio"
        condition: "< 0.2"
        severity: "medium"
        action: "review_signal_quality"

  # Evolution confidence scoring
  confidence:
    enabled: true
    
    # Factors that affect evolution confidence
    factors:
      signal_count:
        weight: 0.3
        thresholds: {low: 1, medium: 3, high: 5}
        
      signal_consistency:
        weight: 0.2
        description: "Same-type signals from different contexts"
        
      historical_success:
        weight: 0.3
        description: "Success rate of similar past evolutions"
        
      scope_risk:
        weight: 0.2
        description: "Lower confidence for kernel-level changes"
        
    # Confidence thresholds for action
    action_thresholds:
      auto_apply: 0.8   # High confidence: can auto-apply (with audit)
      recommend: 0.5    # Medium confidence: recommend for human review
      investigate: 0.3  # Low confidence: needs investigation before action
